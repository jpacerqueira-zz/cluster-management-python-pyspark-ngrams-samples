
 1.) Execute pyspark2 sample as :

    - Spark SQL 
    [joao.cerqueira@ixpbda09 basketball]$ ./pyspark2-testshell.sh

    - Spark with Apache Hive Context
    [joao.cerqueira@ixpbda09 basketball]$ ./pyspark2-hiveOnSpark.sh 
    
 2.) You can Follow FrameWorks:
 
   - of SparkSQL ( recommended for raw/stage Parquet Files ) :
     
    http://spark.apache.org/docs/latest/sql-programming-guide.html
    http://spark.apache.org/docs/latest/sql-programming-guide.html#saving-to-persistent-tables
    
   -  or ApacheHive Context DataBases ( recommended for staged/published Tables ) :
   
   http://spark.apache.org/docs/latest/sql-programming-guide.html#hive-metastore-parquet-table-conversion
